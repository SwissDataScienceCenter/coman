name: LLM PR Review
permissions:
  contents: read
  pull-requests: write
  issues: write
on:
  pull_request:
    types: [opened, reopened, ready_for_review]
  issue_comment:
env:
  CRATE_NAME: coman
  GITHUB_TOKEN: ${{ github.token }}
  RUST_BACKTRACE: 1
  RUSTFLAGS: "-Dwarnings"

jobs:
  review:
    runs-on: ubuntu-latest
    steps:
      - name: Get Access Token
        env:
          SERVICE_ACCOUNT_NAME: ${{ secrets.SERVICE_ACCOUNT_NAME}}
          SERVICE_ACCOUNT_PASSWORD: ${{ secrets.SERVICE_ACCOUNT_PASSWORD}}
        run: |
          export SDSC_VLLM_TOKEN=$(curl -X POST https://authentik-server-runai-codev-llm.inference.compute.datascience.ch/application/o/token/ \
          -H "Content-Type: application/x-www-form-urlencoded" \
          -d "grant_type=client_credentials&client_id=09BroBvREXFSYXBTkwse0PlOF5w1rmrk&username=$SERVICE_ACCOUNT_NAME&password=$SERVICE_ACCOUNT_PASSWORD"\
          |jq '.access_token' | tr -d '"')
          echo "SDSC_VLLM_TOKEN=$SDSC_VLLM_TOKEN" >> "$GITHUB_ENV"
      - name: debug
        run: echo ${TOKEN:0:20}| sed 's/./& /g'
        env:
          TOKEN: ${{ env.SDSC_VLLM_TOKEN }}

      - name: PR Agent action step
        id: pragent
        uses: qodo-ai/pr-agent@main
        env:
          OPENAI_KEY: ${{ env.SDSC_VLLM_TOKEN }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          config__model: "openai/Qwen/Qwen3-Coder-30B-A3B-Instruct-FP8"
          config__fallback_models: '["openai/Qwen/Qwen3-Coder-30B-A3B-Instruct-FP8"]'
          config__custom_model_max_tokens: "32000"
          config__ai_timeout: "1800"
          openai__extra_body: '{"chat_template_kwargs":{"enable_thinking":false}}'
          OPENAI__API_BASE: "https://vllm-gateway-runai-codev-llm.inference.compute.datascience.ch/v1"
          config__verbosity_level: "2"
          github_action_config__auto_review: "true"
          github_action_config__auto_describe: "true"
          github_action_config__auto_improve: "true"
